{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining and Exploration [INFR11007]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Performance evaluation and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we look at various performance metrics for classification.  We then turn our attention to cross-validation and hyper-parameter tuning. Finally, we touch on Bayesian optimisation for hyper-parameter tuning.\n",
    "\n",
    "As always, let's start by importing the basic packages and modules we will need :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "from __future__ import division, print_function # Imports from __future__ since we're running Python 2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "random_state = 10 # Ensure reproducible results\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification performance evaluation\n",
    "In this lab, we will look at the following classification metrics:\n",
    "* classification accuracy\n",
    "* logarithmic loss\n",
    "* confusion matrices\n",
    "\n",
    "As always, we will make use of the familiar [landsat satellite](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Landsat+Satellite%29) dataset which is 36-dimensional and comprises 6 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landsat sattelite data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1 ==========\n",
    "Load the `landsat_train.csv` dataset into a `pandas` DataFrame called  `landsat_train_full`, and the `landsat_test.csv` dataset into a DataFrame called `landsat_test`. Display the shapes of the two DataFrames. \n",
    "\n",
    "*Hint: The DataFrames should have 37 columns including the class labels, and 4435 and 2000 entries for the training and testing datasets, respectively.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4435 entries and 37 columns in the landsat_train DataFrame\n",
      "There are 2000 entries and 37 columns in the landsat_test DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "path_train_full = os.path.join(os.getcwd(), 'datasets', 'landsat', 'landsat_train.csv')\n",
    "path_test = os.path.join(os.getcwd(), 'datasets', 'landsat', 'landsat_test.csv')\n",
    "landsat_train_full = pd.read_csv(path_train_full, delimiter = ',')\n",
    "landsat_test = pd.read_csv(path_test, delimiter = ',')\n",
    "print(\"There are {} entries and {} columns in the landsat_train DataFrame\"\\\n",
    "      .format(landsat_train_full.shape[0], landsat_train_full.shape[1]))\n",
    "print(\"There are {} entries and {} columns in the landsat_test DataFrame\"\\\n",
    "      .format(landsat_test.shape[0], landsat_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2 ==========\n",
    "Load the dataset class names stored in `landsat_classes.csv'` into a dictionary. You are free to choose whatever method you wish. \n",
    "\n",
    "Replace the label numbers in both the `landsat_train_full` and `landsat_test` DataFrames with the corresponding class names.\n",
    "\n",
    "*Hint: If unsure, check out the provided solutions for Lab 3.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels dictionary:\n",
      "{1: 'red soil', 2: 'cotton crop', 3: 'grey soil', 4: 'damp grey soil', 5: 'soil with vegetation stubble', 6: 'mixture class (all types present)', 7: 'very damp grey soil'}\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "labels_path = os.path.join(os.getcwd(), 'datasets', 'landsat', 'landsat_classes.csv') # Load data\n",
    "landsat_labels = pd.read_csv(labels_path, delimiter = ',', index_col=0) # Load csv file\n",
    "landsat_labels_dict = landsat_labels.to_dict()[\"Class\"] # Convert to dictionary\n",
    "print(\"Labels dictionary:\\n{}\".format(landsat_labels_dict)) # Print dictionary\n",
    "landsat_train_full.replace({'label' : landsat_labels_dict}, inplace=True) # Perform replacement (train)\n",
    "landsat_test.replace({'label' : landsat_labels_dict}, inplace=True) # Perform replacement (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3 ==========\n",
    "Store the training features, training labels, testing features and testing labels into numpy arrays `X_train_full`, `y_train_full`, `X_test`, and `y_test` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "X_train_full = landsat_train_full.drop('label', axis=1).values.astype(np.float) # Training features\n",
    "y_train_full = landsat_train_full['label'].values # Training labels\n",
    "X_test = landsat_test.drop('label', axis=1).values.astype(np.float) # Training features\n",
    "y_test = landsat_test['label'].values # Training labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out validation\n",
    "We currently have two datasets, namely `X_train_full` and `X_test`. If we just wanted to train a simple classifier with default settings and evaluate performance on the test subset, then our current approach should be good enough. \n",
    "\n",
    "Even simple classifiers, however, have hyper-parameters that need to be carefully tuned. In order to do so, we need a separate validation subset of the data which should be different from the training set. We should never perform model (i.e. hyper-parameter) selection by using the test set, because if we do so, we won't be able to evaluate the generalisation of our model on unseen data (and yes, in case you are wondering, that means that by performing model selection we might in a way *overfit* on the validation set).\n",
    "\n",
    "The simplest approach we can follow is to split our data three-way, that is, have a training, a validation, and a test set. We are already given the test set, so all we need to do is to split our training set (which we have called `train_full`) into training and validation subsets.\n",
    "\n",
    "Thankfully, sklearn offers an implementation of this operation which is called [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). By default, this function will shuffle our data before splitting it. The `test_size` input parameter indicates the relative size of the test set (which will be used as the validation set in our case) and the `random_state` parameter can be used to ensure we can get reproducible results if we call this function multiple times.\n",
    "\n",
    "Let's transform our full training set into two subsets called `train` and `val`. We will feed in our `X_train_full` and `y_train_full` arrays and call the new arrays `X_train`, `X_val`,  `y_train`, and `y_val`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, \n",
    "                                                  test_size=0.33, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature standardisation\n",
    "\n",
    "We have already seen that [feature standardisation](http://scikit-learn.org/stable/modules/preprocessing.html) (i.e. transforming the data so that they have zero mean and unit variance) is important for some unsupervised dimensionality reduction methods. It turns out that it is also crucial for the training efficiency of many supervised algorithms, especially those that use some form of optimisation (e.g. logistic regression trained via gradient descent). \n",
    "\n",
    "Feature standardisation can hardly ever do any harm when it comes to training classifiers, so it is generally good practice to deploy it as a first step in our data processing pipeline.\n",
    "\n",
    "It is essential, however, to perform feature standardisation by using the training data only. If we use the whole dataset for estimating feature means and variances, we will have information leakage from the test set to the training set, and our results might be over-optimistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 4 ==========\n",
    "Create a [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) instance and fit it by using the training features only (`X_train`). \n",
    "\n",
    "Then by using the object you just fit, standardise (i.e. call the `transform()` method) the training, validation and test input features and save the results into three new numpy arrays, `X_train_sc`, `X_val_sc` and `X_test_sc`.\n",
    "\n",
    "*Hint: If unsure how to perform this step, check out Lab 3.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler().fit(X_train)\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_val_sc = sc.transform(X_val)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes classification\n",
    "Now we want to use a simple Gaussian Naive Bayes classifier to get a feel for the  performance baseline we can achieve on our validation set. Read about the [Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) and the underlying assumption if you are not already familiar with it.\n",
    "\n",
    "We will make use of the `GaussianlNB` class in sklearn. **Check out the user guide [description](http://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes) and [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) to familiarise yourself with this class.**\n",
    "\n",
    "All classifier objects in sklearn implement a `fit()` and `predict()` method. The first learns the parameters of the model and the latter classifies inputs. For a Naive Bayes classifier, the [`fit()`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB.fit) method takes at least two input arguments `X` and `y`, where `X` are the input features and `y` are the labels associated with each example in the training dataset (i.e. targets). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our classifier by calling its `fit()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['grey soil', 'grey soil', 'cotton crop', ..., 'red soil',\n",
       "       'grey soil', 'cotton crop'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn model objects have built in scoring methods. The default [`score()`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB.score) method for `GaussianNB` estimates classification accuracy. Alternatively, we can compute the prediction for the test data and make use of the [`accuracy_score()`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function (that is in fact what the classifier's `score()` method does under the hood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB classification accuracy on validation set (by using the accuracy_score() function): 0.791\n",
      "GNB classification accuracy on validation set (by using the model's score() method): 0.791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# By using the predict() method and accuracy_score metric\n",
    "gnb_prediction = gnb.predict(X_val_sc)\n",
    "gnb_accuracy = accuracy_score(y_val, gnb_prediction) # The accuracy_score() function takes as inputs\n",
    "                                                 # the true labels and the predicted ones\n",
    "\n",
    "# By using the score() method\n",
    "gnb_accuracy_alt = gnb.score(X_val_sc, y_val) # The score() method takes as inputs \n",
    "                                              # the test input features and the associated (true) labels\n",
    "\n",
    "# Print results\n",
    "print(\"GNB classification accuracy on validation set (by using the accuracy_score() function): {:.3f}\"\n",
    "      .format(gnb_accuracy))\n",
    "print(\"GNB classification accuracy on validation set (by using the model's score() method): {:.3f}\"\n",
    "      .format(gnb_accuracy_alt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 5 [optional] ==========\n",
    "Write your own function for computing classification accuracy by taking as inputs the vector of the true labels `y_true` and the vector of predicted labels `y_pred`. Compare its outcome to the results from using the scikit-learn `accuracy_score` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "def my_classification_accuracy(y_true, y_pred):\n",
    "    \"\"\"Computes classification accuracy.\n",
    "    \n",
    "    y_true : list or array\n",
    "        vector with true labels\n",
    "        \n",
    "    y_pred : list or array\n",
    "        vector with predicted labels\n",
    "        \n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    assert y_true.shape == y_pred.shape, \"Arrays must be of equal shape.\"\n",
    "    return np.sum(y_true == y_pred) / y_true.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB classification accuracy on test set (by using the custom function): 0.791\n"
     ]
    }
   ],
   "source": [
    "# Double-check that results come out as expected\n",
    "print(\"GNB classification accuracy on test set (by using the custom function): {:.3f}\"\n",
    "      .format(my_classification_accuracy(y_val, gnb_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classification [optional]\n",
    "\n",
    "How can we know if the performance of our classifier is vaguely good or bad? One simple idea is to try to compare its performance to a baseline.\n",
    "\n",
    "### ========== Question 6 [optional] ==========\n",
    "\n",
    "What is the simplest classifier you can think of? (Try for a moment to forget everything you know about machine learning and think how you would classify test inputs in the simplest, and perhaps dumbest, way).\n",
    "\n",
    "Implement the baseline classifier of your choice and compute its classification accuracy on the validation set. Does the GNB model perform better than the baseline?\n",
    "\n",
    "This might seem as an unnecessary hassle at this point, but it is important to always check what the baseline performance level is for a given task. There are cases where you can spend hours optimising a classifier, only to find out later on, that its performance does not exceed the baseline (i.e. because the input features, for instance, are not informative of the labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classification accuracy on validation set (most frequent class): 0.230\n",
      "Baseline classification accuracy on validation set (uniformly random prediction): 0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uss2f\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:250: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# Predict always the most frequent class\n",
    "from scipy.stats import mode # Computes the mode of a signal\n",
    "from sklearn.metrics import accuracy_score\n",
    "dominant_class = mode(y_train).mode[0]\n",
    "y_my_dummy = [dominant_class] * X_val_sc.shape[0]\n",
    "\n",
    "# Make uniformly random predictions\n",
    "np.random.seed(random_state) # Set random seed to ensure reproducibility\n",
    "labels = np.unique(y_train)\n",
    "random_prediction_int = np.random.randint(0, labels.size, y_val.size)\n",
    "random_prediction_cat = np.zeros((y_val.size,), dtype='O')\n",
    "for sample in np.arange(y_val.size):\n",
    "    random_prediction_cat[sample] = labels[random_prediction_int[sample]]\n",
    "\n",
    "\n",
    "print(\"Baseline classification accuracy on validation set (most frequent class): {:.3f}\".\n",
    "      format(accuracy_score(y_val, y_my_dummy)))\n",
    "print(\"Baseline classification accuracy on validation set (uniformly random prediction): {:.3f}\".\n",
    "      format(accuracy_score(y_val, random_prediction_cat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "The simplest classifier is to classify everything as the most frequent class in the training set. The accuracy of this classifier is 0.23 on the validation set, therefore we can be certain that our GNB classifier performs better than chance.\n",
    "\n",
    "Another option is to make uniformly random predictions. This classifier will yield an even lower accuracy score on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 7 [optional] ==========\n",
    "\n",
    "It turns out that sklearn implements the [`DummyClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) class which offers sever choices for dummy classifiers (`strategy` parameter).  Is the baseline classifier you came up with in the previous question included in this class? If so, double-check that your estimate about baseline performance matches the one returned by the `DummyClassifier` in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classification accuracy on validation set (most frequent class): 0.230\n",
      "Baseline classification accuracy on validation set (random prediction): 0.154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "# Your code goes here\n",
    "\n",
    "# most_frequent strategy\n",
    "dcl_mf = DummyClassifier(strategy='most_frequent')\n",
    "dcl_mf.fit(X_train_sc, y_train) # Clf user guide for alternative strategy options\n",
    "y_most_frequent = dcl_mf.predict(X_val)\n",
    "\n",
    "# uniformly random prediction strategy\n",
    "# Set random_state parameter to ensure reproducibility\n",
    "dcl_rnd = DummyClassifier(strategy='uniform', random_state=10).fit(X_train_sc, y_train) \n",
    "y_random = dcl_rnd.predict(X_val)\n",
    "\n",
    "print(\"Baseline classification accuracy on validation set (most frequent class): {:.3f}\".\n",
    "      format(accuracy_score(y_val, y_most_frequent)))\n",
    "print(\"Baseline classification accuracy on validation set (random prediction): {:.3f}\".\n",
    "      format(accuracy_score(y_val, y_random)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "Scikit-learn also has a [`confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) implementation which returns a numpy array (square matrix) of dimensionality `K`, where `K` is the number of classes (`6` in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 8 ========== \n",
    "By using the prediction of the Gaussian Naive Bayes model, compute and display the confusion matrix on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[150   0   0   4  11   1]\n",
      " [  0  85  23   2   1  19]\n",
      " [  0  25 291   7   0   3]\n",
      " [  1   0  10 264  62   0]\n",
      " [  2   8   0  14  95  20]\n",
      " [  0  66   3   0  24 273]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Your code goes here\n",
    "cm = confusion_matrix(y_val, gnb_prediction)\n",
    "print('Confusion matrix\\n{}'.format(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided with the following function which uses  `seaborn's` [`heatmap`](http://seaborn.pydata.org/generated/seaborn.heatmap.html) function to visualise a confusion matrix. The parameter `normalize` can be used to  convert the rows of the confusion matrix  into normalised prediction scores/probabilities (i.e. the sum of each row will be equal to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix by using seaborn heatmap function\n",
    "def plot_confusion_matrix(cm, normalize=False, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\n",
    "    \n",
    "    If normalize is set to True, the rows of the confusion matrix are normalized so that they sum up to 1.\n",
    "    \n",
    "    \"\"\"\n",
    "    if normalize is True:\n",
    "        cm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "        vmin, vmax = 0., 1.\n",
    "        fmt = '.2f'\n",
    "    else:\n",
    "        vmin, vmax = None, None\n",
    "        fmt = 'd'\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=vmin, vmax=vmax, \n",
    "                    annot=True, annot_kws={\"fontsize\":9}, fmt=fmt)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 9 ========== \n",
    "\n",
    "Use the provided `plot_confusion_matrix` to visualise the confusion matrix on the test dataset. Make two calls of the function, one with the `normalize` parameter set to `True`, and another one with the same parameter set to `False`. Use a single figure with two subplots. Inspect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uss2f\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py:143: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if xticklabels == []:\n",
      "C:\\Users\\uss2f\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py:151: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if yticklabels == []:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAFgCAYAAADDzb9SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPUmSpD5msydJktTH/gcyOftQbsZXbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd0863c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "plot_confusion_matrix(cm, normalize=False, \\\n",
    "                      classes=gnb.classes_) # un-normalized\n",
    "ax2 = fig.add_subplot(122)\n",
    "plot_confusion_matrix(cm, normalize=True, \\\n",
    "                      classes=gnb.classes_, title='Normalised confusion matrix') # normalized\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cotton crop', 'damp grey soil', 'grey soil', 'red soil',\n",
       "       'soil with vegetation stubble', 'very damp grey soil'], \n",
       "      dtype='<U28')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy (logistic) loss\n",
    "Classification accuracy is not the only metric used to evaluate classification performance, and in many cases, it can be very misleading. One such case is when we deal with unbalanced datasets in binary classification tasks. In this case, we might want to use different metrics such as [precision](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score), [recall](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score), [F1-score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) and/or [area under the ROC curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html). Unfortunately, we won't have time to cover all these in the current lab, but you are free to experiment with them if you are keen.\n",
    "\n",
    "Another particular case where the accuracy metric is not very useful, is when we care not only about the classification predictions, but also about the associated probability distributions. Sometimes, for instance, we might consider that it is not catastrophic to do a misclassification, as long the associated prediction probability is not too high. In other words, we might want to penalise wrong classifications that are made with high confidence more than misclassifications that are made with low confidence.\n",
    "\n",
    "One metric that takes into account the prediction probabilities is the [logarithmic loss or cross-entropy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html).  This metric is very often used as the evaluation score in [data science competitions](https://www.kaggle.com/wiki/LogarithmicLoss). You might recognise this metric as the loss funcion used while training logistic regression models and neural networks.\n",
    "\n",
    "### ========== Question 10 ========== \n",
    "\n",
    "By using the [log-loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) implementation in sklearn, compute the log-loss scores for the Dummy and Gaussian Naive Bayes classifers from Questions 6 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss scores:\n",
      "Dummy classifier 26.588252047175107\n",
      "Gaussian Naive Bayes classifier 4.057455891821185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "# Your code goes here\n",
    "pred_proba_dummy = dcl_mf.predict_proba(X_val_sc)\n",
    "pred_proba_gnb = gnb.predict_proba(X_val_sc)\n",
    "print(\"Log-loss scores:\\nDummy classifier {}\\nGaussian Naive Bayes classifier {}\".\n",
    "      format(log_loss(y_val, pred_proba_dummy), log_loss(y_val, pred_proba_gnb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier comparison\n",
    "Now we want to compare the performance of different types of classifiers on the validation set. This is a common first step to decide which classifier might be most suitable for the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 11 ========== \n",
    "\n",
    "Compare the classification accuracy of various types of classifiers of your choice (at least three different types) on the landsat dataset. Use the training set for training classifiers  and the validation set to evaluate performance. \n",
    "\n",
    "Log and print the classification accuracy and cross-entropy (aka logarithmic loss) scores for each classifier. \n",
    "\n",
    "*Reminder: Make sure you make use of the standardised versions of the data, i.e. `X_train_sc` and `X_val_sc`. *\n",
    "\n",
    "*Hint:  You might find this `sklearn` [tutorial](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) very useful.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set:\n",
      "Logistic Regression, accuracy: 0.837, log-loss: 0.490\n",
      "Nearest Neighbors, accuracy: 0.889, log-loss: 0.423\n",
      "Linear SVM, accuracy: 0.867, log-loss: 0.337\n",
      "RBF SVM, accuracy: 0.893, log-loss: 0.282\n",
      "Decision Tree, accuracy: 0.844, log-loss: 3.233\n",
      "Random Forest, accuracy: 0.898, log-loss: 0.284\n",
      "Neural Net (Multi-layer perceptron), accuracy: 0.902, log-loss: 0.249\n",
      "Naive Bayes, accuracy: 0.791, log-loss: 4.057\n",
      "LDA, accuracy: 0.833, log-loss: 0.784\n",
      "QDA, accuracy: 0.855, log-loss: 0.980\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "names = [\"Logistic Regression\", \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net (Multi-layer perceptron)\",\n",
    "         \"Naive Bayes\", \"LDA\", \"QDA\"]\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(n_neighbors=9),\n",
    "    SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "    SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state),\n",
    "    MLPClassifier(random_state=random_state),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "ca_score = {} # Classification accuracy\n",
    "ce_score = {} # Cross-entropy\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "    ca_score[name] = clf.score(X_val_sc, y_val)\n",
    "    ce_score[name] = log_loss(y_val, clf.predict_proba(X_val_sc))\n",
    "print('Classification performance on validation set:')\n",
    "for clf in names:\n",
    "    print (\"{}, accuracy: {:.3f}, log-loss: {:.3f}\".format(clf, ca_score[clf], ce_score[clf]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 12 ========== \n",
    "\n",
    "Which classifier seems to perform best on the validation set? \n",
    "\n",
    "Are your observations as expected, or do you find them rather suprising? \n",
    "\n",
    "Would you trust the results of this  comparison?  If not, explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "In terms of classification accuracy, it seems that the Neural Net classifier performs best at this point (although results might depend on how we set the `random_state` parameter). The performances of the Random Forest and SVM classifiers (with RBF kernel) also rank very highly.\n",
    "\n",
    "In terms of cross-entropy loss, the neural net again yields the highest performance (i.e lowest log-loss). This should not be suprising, since it is exactty this score that is minimised during the training of a neural network (and a logistic regression classifier of course, but a neural network with hidden layers provides more flexibility in fitting models due to making use of non-linearities in the data).\n",
    "\n",
    "We should not,  however, trust the results of this analysis too much. The first reason is that, with few exceptions, most of the classifiers deployed here have many hyper-parameters, the setting thereof dramatically affects the classifier's performance. Since we have not tuned these hyper-parameters in a systematic way, we should not draw any generic conclusions about the  performance of the classifiers. \n",
    "\n",
    "Another reason is that we have compared the performance of the various classifiers on a specific subset of the data. Hence, we have only computed an approximation of the generalisation error on unseen data. Thankfully, in our case, the validation set is relatively large (~1460 data points), so we have reasons to believe that this might be a relatively good approximation. If we wanted this approximation to be as accurate as possible, we should have used K-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to optimise the hyper-parameters of classifiers we should never do so by using the test set. If we compare the performance of various classifiers -after we have tuned their hyper-parameters- by using a validation set, we should equally not use the same set for parameter optimisation. \n",
    "\n",
    "Instead, we should use two independent procedures for hyper-parameter tuning and classifier comparison. For instance, we could split again our training set into two subsets and use the former to train classifiers under various parameter configurations and the latter to assess performance. Then by picking the parameter settings which gave optimal results for each classifier, we can compare the performance of the best-performing models on our original validation set. \n",
    "\n",
    "Alternatively, we can use [K-fold cross-validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) on the training set for setting hyper-parameters; this approach will yield slightly more reliable results, since hyper-parameter selection will be based on averaging across a few runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn offers a very convenient tool for fitting model hyperparameters called [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Spend a few minutes reading the documentation of this class and make sure you understand how it works.\n",
    "\n",
    "A `GridSearchCV` classifier is constructed by defining the following parameters, among others:\n",
    "* `estimator`: this is another (base) classifier which has been constructed but not fitted yet.\n",
    "* `param_grid`: this is a dictionary, where the different hyper-parameters to be optimised are defined, as well as the search space for each hyper-parameter, which can be either discrete or continuous.\n",
    "* `scoring`: this is a string defining the objective function (i.e. scoring method) to be used for hyper-parameter optimisation. Some options are `accuracy` for classification accuracy, `neg_log_loss` for log-loss, or user-defined metrics. A list of all the available metrics can be found [here](http://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "* `cv`: cross-validation to be used for optimising the hyper-parameters. This can be either an integer `K` or a sklearn cross-validation generator. If an integer is provided, then `KFold` cross-validation will be used. By default sklearn will use 3-fold CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make a first attempt to optimise the regularisation parameter `C` of an [`SVM`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) classifier with an RBF kernel. \n",
    "\n",
    "Spend a few moments to understand what the following piece of code does. You can hopefully  see that after we have fitted a `GridSearchCV` classifier, we can access the best scores achieved and best-scoring parameter configurations by looking at the `best_params_` and `best_score_` attributes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best setting of C parameter for SVC with RBF kernel: 100.0\n",
      "Best cross-validated score: 0.898\n",
      "Classification accuracy on validation set: 0.911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "svc = SVC(kernel='rbf')\n",
    "parameters = {'C': np.logspace(-3,3,7)}\n",
    "svc_clf = GridSearchCV(estimator=svc, cv=cv, param_grid=parameters, scoring='accuracy')\n",
    "svc_clf.fit(X_train_sc, y_train)\n",
    "print(\"Best setting of C parameter for SVC with RBF kernel: {}\".format(svc_clf.best_params_[\"C\"]))\n",
    "print(\"Best cross-validated score: {:.3f}\".\n",
    "      format(svc_clf.best_score_))\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(svc_clf.score(X_val_sc,y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ========== Question 13 ========== \n",
    "\n",
    "By adapting the above code provided, optimise both the regularisation parameter `C` and the kernel coefficient `gamma` of an SVM classifier with RBF kernel. \n",
    "\n",
    "For `C`, you can use the previous grid, and for `gamma` you can use a logarithmic range between $10^{-4}$ to $10^{1}$.\n",
    "\n",
    "Print the best scoring parameter configuration and the classification accuracy score on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVC with RBF kernel, C: 10.0, gamma: 0.1\n",
      "Best cross-validated score: 0.9074385728710872\n",
      "Classification accuracy on validation set: 0.917\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "svc = SVC(kernel='rbf')\n",
    "parameters = {'C': np.logspace(-3,3,7), 'gamma' : np.logspace(-4, 1, 6)}\n",
    "svc_clf = GridSearchCV(estimator=svc, cv=cv, param_grid=parameters, scoring='accuracy')\n",
    "svc_clf.fit(X_train_sc, y_train)\n",
    "print(\"Best parameters for SVC with RBF kernel, C: {}, gamma: {}\".\n",
    "      format(svc_clf.best_params_[\"C\"], svc_clf.best_params_[\"gamma\"]))\n",
    "print(\"Best cross-validated score: {}\".\n",
    "      format(svc_clf.best_score_))\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(svc_clf.score(X_val_sc,y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 14 ========== \n",
    "\n",
    "How does the performance on the validation set compare to that achieved previously with other classifers? \n",
    "\n",
    "If you did not want to use the provided `GridSearchCV` and `KFold` modules from sklearn but wanted to write your own code from scratch, how many *for loops* would you have included in your code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "The performance attained by the SVM classifier on the validation set after tuning the `C` and `gamma` parameters via cross-validation is the highest achieved so far. Once again, results will depend on how we set the random seed, so they might be slightly different if you set it to a different number.\n",
    "\n",
    "If we were to write the code from scratch, we would need three for-loops; one for looping over the possible `C` values, another one for looping over the `gamma` values, and a final one for looping over the different training/validation folds, as part of the cross-validation procedure. You will appreciate that, among others, one particular advantage of using the sklearn modules is that we can write cleaner code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 15 [Optional] ========== \n",
    "\n",
    "Optimise the number of hidden units and regularisation constant `alpha` of an [MLP classifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) with one hidden layer. Use the `neg_log_loss` as the scoring function, which will perform hyper-parameter optimisation by minimising the log-loss (i.e. cross-entropy). Use default settings for the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLP classifier: hidden layer size: (100,), alpha: 0.1, best cross-validated score: -0.291\n",
      "Classification accuracy on validation set: 0.889\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# Ignore ConvergenceWarnings from sklearn\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning) \n",
    "\n",
    "# MLP with variable hidden layer size and alpha, score: log-loss\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "mlp = MLPClassifier(random_state=random_state)\n",
    "parameters = {'hidden_layer_sizes' : [(10,), (100,), (1000,)], 'alpha' : np.logspace(-8,0,9)}\n",
    "mlp_clf = GridSearchCV(mlp, param_grid=parameters, scoring='neg_log_loss')\n",
    "mlp_clf.fit(X_train_sc, y_train)\n",
    "print(\"Best parameters for MLP classifier: hidden layer size: {}, alpha: {}, best cross-validated score: {:.3f}\".\n",
    "      format(mlp_clf.best_params_[\"hidden_layer_sizes\"], mlp_clf.best_params_[\"alpha\"], mlp_clf.best_score_))\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(accuracy_score(y_val, mlp_clf.predict(X_val_sc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 16 [Optional] ========== \n",
    "\n",
    "Why is the classification accuracy not better than the one achieved in Question 11? Did we do something wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "We did not do anything wrong. The reason why our classification accuracy did not improve is that we we have been optimising for the negative log-loss score and not for classification accuracy, hence our algorithm selected those hyper-parameters that minimised the log-loss and not the ones that would have maximised classification accuracy. \n",
    "\n",
    "The selection of the objective function (aka score) is **extremely** important for hyper-parameter optimisation, and depends upon the task at hand. There are no hard rules here. But it is generally a good idea to optimise your models with regards to the same objective function that will be finally used to assess performance.\n",
    "\n",
    "Let's now have a look at what hyper-parameter configuration we would have ended up with, should we have chosen to maximise classification accuracy instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLP classifier: hidden layer size: (1000,), alpha: 0.01, best cross-validated score: 0.900\n",
      "Classification accuracy on validation set: 0.904\n"
     ]
    }
   ],
   "source": [
    "# MLP with variable hidden layer size and alpha, score: accuracy\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "mlp = MLPClassifier(random_state=random_state)\n",
    "parameters = {'hidden_layer_sizes' : [(10,), (100,), (1000,)], 'alpha' : np.logspace(-8,0,9)}\n",
    "mlp_clf = GridSearchCV(mlp, param_grid=parameters, scoring='accuracy')\n",
    "mlp_clf.fit(X_train_sc, y_train)\n",
    "print(\"Best parameters for MLP classifier: hidden layer size: {}, alpha: {}, best cross-validated score: {:.3f}\".\n",
    "      format(mlp_clf.best_params_[\"hidden_layer_sizes\"], mlp_clf.best_params_[\"alpha\"], mlp_clf.best_score_))\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(accuracy_score(y_val, mlp_clf.predict(X_val_sc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy has now improved as compared to using default settings. Note that the selection of hyper-parameters can significantly differ, depending upon the objective function used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian optimisation is a strategy for optimising black-box functions without the need for computing derivatives. Bayesian optimisation methods can prove very useful for optimising the hyper-parameters of machine learning models in arbitrary search spaces, for both continuous and discrete-valued hyper-parameters.\n",
    "\n",
    "In this final section, we will use the [`scikit-optimize`](https://scikit-optimize.github.io) package to tune the `C` and `gamma` hyper-parameters of an SVM classifier with RBF kernel (see Question 13). We will use a Gaussian Process prior over the average cross-validated classification accuracy score, and will try to maximise this metric by tuning the SVM hyper-parameters. \n",
    "\n",
    "Spend a few moments trying to understand what the following piece of code does. If something is not clear, you can consult the skopt [documentation and examples](https://scikit-optimize.github.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state) # We want to use 3-fold CV to compute the loss in each iteration\n",
    "svc_clf = SVC(kernel='rbf') # Constructor without defining hyper-parameters just yet\n",
    "\n",
    "def objective_svc(params): # Here we define the metric we want to minimise\n",
    "    C, gamma = params\n",
    "    svc_clf.set_params(C=C, \n",
    "                      gamma=gamma) # Set the parameters of the clf\n",
    "    \n",
    "    return -np.mean(cross_val_score(svc_clf, X_train_sc, y_train, cv=cv, n_jobs=-1,\n",
    "                                    scoring=\"accuracy\")) # We want to maximise average accuracy, i.e. minimise minus average accuracy\n",
    "\n",
    "# Search space for the two parameters\n",
    "space  = [(10**-3, 10**3, \"uniform\"), # C\n",
    "          (10**-4, 10**1, \"uniform\")] # gamma\n",
    "\n",
    "# Initial values (optional)\n",
    "x0 = [1, 10**-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code uses the above defined cost function (`objective_scv`) and the skopt `gp_minimise` function to select the best hyper-parameter configuration in the defined search space. The input parameters are as follows:\n",
    "* `func`: function that we wish to minimise\n",
    "* `dimensions`: the search space for the hyper-parameters\n",
    "* `x0`: inital values for the hyper-parameters\n",
    "* `n_calls`: number of times the function will be evaluated\n",
    "* `random_state`: random seed\n",
    "* `n_random_starts`: before we start modelling the optimised function with a GP Regression model, we want to try a few random choices for the hyper-parameters.\n",
    "* `kappa`: trade-off between [exploration vs. exploitation](https://en.wikipedia.org/wiki/Multi-armed_bandit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-81428045ce09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mskopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m res_gp = gp_minimize(func=objective_svc, dimensions=space, x0=x0, \n\u001b[1;32m      3\u001b[0m                      n_calls=25, random_state=random_state, n_random_starts=5, kappa=1.9)\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best score with Bayesian optimisation: {:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mres_gp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print(\"Best parameters with Bayesian optimisation:\\nC: {}\\ngamma: {}\"\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(func=objective_svc, dimensions=space, x0=x0, \n",
    "                     n_calls=25, random_state=random_state, n_random_starts=5, kappa=1.9)\n",
    "print(\"Best score with Bayesian optimisation: {:.3f}\".format(-res_gp.fun))\n",
    "print(\"Best parameters with Bayesian optimisation:\\nC: {}\\ngamma: {}\"\n",
    "      .format(res_gp.x[0],res_gp.x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the skopt `plot_convergence` function, we can plot the objective function (i.e. evaluated cross-validated accuracy score) against the number of iterations of the Bayesian optimisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "plt.figure(figsize=(5,2))\n",
    "plot_convergence(res_gp)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to clarify here, that the plot above shows the minimum value of the optimised function achieved at step $n$. Nevertheless, this does not mean that at a certain step the objective function should always decrease as compared to the previous step (as is the case with e.g. with gradient descent). \n",
    "\n",
    "If we wish to plot the value of the evaluated function $f \\left (x \\right)$ vs. the iteration number $n$, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,2))\n",
    "plt.plot(res_gp.func_vals)\n",
    "plt.scatter(range(len(res_gp.func_vals)), res_gp.func_vals)\n",
    "plt.ylabel(r'$f(x)$')\n",
    "plt.xlabel('Number of calls $n$')\n",
    "plt.xlim([0, len(res_gp.func_vals)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy on the validation set by using the selected hyper-parameter configuration. Since we are not performing any further comparisons or hyper-parameter optimisation, we can finally use the test set to report the performance of our selected method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_opt = SVC(kernel='rbf',\n",
    "             C=res_gp.x[0],\n",
    "             gamma=res_gp.x[1]).fit(X_train_sc,y_train)\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(accuracy_score(y_val, svc_opt.predict(X_val_sc))))\n",
    "print(\"Classification accuracy on test set: {:.3f}\".format(accuracy_score(y_test, svc_opt.predict(X_test_sc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to reflect on what we have achieved here. By running only 25 function evaluations (i.e. iterations), we have achieved 0.916 accuracy on the validation set. This is only 0.1%  smaller than the best score achieved with grid search optimisation, where we had to evaluate our cost function 42 times (since we used a 7 X 6 grid). If we allow the GP optimiser to run for more iterations, we might even get higher performance than we can achieve with grid-search, since we are not restricting our hyper-parameters to discrete values, as opposed to grid search optimisation.\n",
    "\n",
    "Finally, it is worth noting that the classification performance scores are slightly different for the validation and test sets. In this part we have not used the validation set to perform hyper-parameter optimisation (remember we used K-fold CV within the training set to do so), hence, we can view `y_val` and `y_test` two as two separate test sets. The computed classification accuracy scores are only approximations of the performance of the classifier on unseen data. The observed difference in performance for the two sets is due to the fluctuation of the approximation when using finite size datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 17 [Optional] ========== \n",
    "\n",
    "Use the skopt package to tune the hyper-parameters of an [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) with one hidden layer (i.e. number of hidden units and `alpha`) via Bayesian optimisation. \n",
    "\n",
    "Finally, report the accuracy of the best parameter configuration on the validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "mlp_clf = MLPClassifier(random_state=random_state)\n",
    "\n",
    "def objective_mlp(params):\n",
    "    number_hidden_units, alpha = params\n",
    "\n",
    "    mlp_clf.set_params(hidden_layer_sizes = (number_hidden_units,),\n",
    "                      alpha=alpha)\n",
    "\n",
    "    return -np.mean(cross_val_score(mlp_clf, X_train_sc, y_train, cv=cv, n_jobs=-1,\n",
    "                                    scoring=\"accuracy\"))\n",
    "\n",
    "space  = [(10, 1000),                       # number of hidden units\n",
    "          (10**-8, 1)]                      # alpha\n",
    "x0 = [100, 10**-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_gp = gp_minimize(objective_mlp, space, x0=x0, n_calls=25, random_state=random_state, n_random_starts=5)\n",
    "print(\"Best score with Bayesian optimisation: {:.3f}\".format(res_gp.fun))\n",
    "print(\"Best parameters with Bayesian optimisation:\\n-hidden layer size: ({},)\\n-alpha: {}\"\n",
    "      .format(res_gp.x[0],res_gp.x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convergence plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plot_convergence(res_gp)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train final model and report accuracy on validation and test sets\n",
    "mlp_opt = MLPClassifier(random_state=random_state,\n",
    "                        hidden_layer_sizes = (res_gp.x[0],),\n",
    "                        alpha=res_gp.x[1])\n",
    "mlp_opt.fit(X_train_sc,y_train)\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(accuracy_score(y_val, mlp_opt.predict(X_val_sc))))\n",
    "print(\"Classification accuracy on test set: {:.3f}\".format(accuracy_score(y_test, mlp_opt.predict(X_test_sc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, note that classification accuracy is slightly worse on the test set.\n",
    "\n",
    "It is also worth noting that, `skopt` can deal with both continuous and discrete hyper-parameters in the same way. In our example, only integer values make sense for the `number_hidden_units` parameter."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
